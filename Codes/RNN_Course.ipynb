{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cPRrKVBQ4mNw",
    "outputId": "75cffeb1-955f-4a79-c00b-4f54f8e52d13"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ykDUOry47Y1",
    "outputId": "aeaa4538-4aeb-4f70-815d-32b06c22d603"
   },
   "outputs": [],
   "source": [
    "cd drive/My\\ Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8g77bIe7wEm"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XBZg48uq4m4t"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "''' path_to_data = '/content/drive/My Drive/MG_time_series.csv' for Google Colab \n",
    "and 'RNN_Course/Data/MG_time_series.csv' for running the codes on the server\n",
    "'''\n",
    "path_to_data = 'Data/MG_time_series.csv'\n",
    "data = pd.read_csv(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7HljgZGrI9Tu",
    "outputId": "cdf9eb9c-44ae-42d8-d125-fe4afac0948a"
   },
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "# data = (data - np.mean(data)) / np.std(data)\n",
    "print(data.shape)\n",
    "\n",
    "# Create sequences\n",
    "def create_dataset(series, time_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(series) - time_steps):\n",
    "        X.append(series[i:i + time_steps])\n",
    "        y.append(series[i + time_steps])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Convert to Numpy if it's a Pandas object\n",
    "if isinstance(data, pd.Series) or isinstance(data, pd.DataFrame):\n",
    "    data = data.values\n",
    "\n",
    "time_steps = 50  # Number of time steps (sliding window)\n",
    "X, y = create_dataset(data, time_steps)\n",
    "\n",
    "\n",
    "# Convert data to PyTorch tensors and reshape for RNN input (samples, time steps, features)\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "X_tensor = torch.from_numpy(X).float()\n",
    "y_tensor = torch.from_numpy(y).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTVAQvofeMU0",
    "outputId": "50b135b2-f338-4269-c50e-e64f13aa18ac"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_tensor, y_tensor, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test set: {X_test.shape}, {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vanilla RNN model\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)  # Initial hidden state\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])  # Take the output from the last time step\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial parameters\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "hidden_sizes = [16, 32, 64, 128]  # Hidden layer sizes to tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "O70lUOcis-h_",
    "outputId": "fe5538eb-bd16-46ca-c142-99f83f4af498"
   },
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the losses for each hidden layer size\n",
    "losses_per_hidden_size = {}\n",
    "\n",
    "# Set initial parameters\n",
    "best_model = None\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Loop over different hidden sizes\n",
    "for hidden_size in hidden_sizes:\n",
    "    model = VanillaRNN(input_size, hidden_size, output_size)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Initialize lists for storing epoch losses\n",
    "    train_loss_epoch = []\n",
    "    val_loss_epoch = []\n",
    "\n",
    "    # Training loop\n",
    "    epochs = 100\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train)\n",
    "        loss = criterion(output, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Append training loss for this epoch\n",
    "        train_loss_epoch.append(loss.item())\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_output = model(X_val)\n",
    "        val_loss = criterion(val_output, y_val)\n",
    "        val_loss_epoch.append(val_loss.item())\n",
    "\n",
    "        # Save the best model\n",
    "        if val_loss.item() < best_val_loss:\n",
    "            best_val_loss = val_loss.item()\n",
    "            best_model = model  # Save the best model\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Hidden Size: {hidden_size}, Training Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")\n",
    "\n",
    "    # Store the training and validation losses for this hidden size\n",
    "    losses_per_hidden_size[hidden_size] = (train_loss_epoch, val_loss_epoch)\n",
    "\n",
    "# Plot training and validation loss for each hidden size\n",
    "save_path = '/content/drive/My Drive/training.pdf'\n",
    "my_color = ['#FF662A', '#FFA22A', '#82AC26', '#4F3F84']\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, hidden_size in enumerate(hidden_sizes):\n",
    "    train_loss, val_loss = losses_per_hidden_size[hidden_size]\n",
    "    plt.plot(train_loss, color=my_color[i], label=f'Training Loss (Hidden Size {hidden_size})', linestyle='solid')\n",
    "    plt.plot(val_loss, color=my_color[i], label=f'Validation Loss (Hidden Size {hidden_size})', linestyle='dashed')\n",
    "\n",
    "plt.title('Training and Validation Loss for Different Hidden Sizes')\n",
    "plt.xlabel('Epochs', fontsize=22)  # X-axis label font size\n",
    "plt.ylabel('Loss', fontsize=22)  # Y-axis label font size\n",
    "plt.xticks(fontsize=18)  # X-axis ticks font size\n",
    "plt.yticks(fontsize=18)\n",
    "\n",
    "# Increase font size for the legend\n",
    "plt.legend(fontsize=18)\n",
    "plt.savefig(save_path, format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 623
    },
    "id": "eYDFk25egGh5",
    "outputId": "211771bf-c66d-4b6d-94d3-b07c959688f9"
   },
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "test_output = best_model(X_test)\n",
    "test_loss = criterion(test_output, y_test)\n",
    "\n",
    "print(f\"Test Loss: {test_loss.item()}\")\n",
    "\n",
    "# Convert tensors to numpy arrays for plotting\n",
    "y_test_np = y_test.detach().numpy()\n",
    "test_output_np = test_output.detach().numpy()\n",
    "\n",
    "# Plot the true vs predicted time series\n",
    "save_path = '/content/drive/My Drive/predicted_vs_true_timeseries.pdf'\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test_np, label='True Time Series', color='#696969')\n",
    "plt.plot(test_output_np, label='Predicted Time Series', color='#FF5500', linestyle='dashed')\n",
    "plt.title('True vs Predicted Time Series', fontsize=22)\n",
    "plt.xlabel('Time Steps', fontsize=22)\n",
    "plt.ylabel('Value', fontsize=22)\n",
    "plt.legend(fontsize=18)\n",
    "\n",
    "# Save the figure as a PDF file\n",
    "plt.savefig(save_path, format='pdf')\n",
    "\n",
    "print(f\"Figure saved as PDF to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SNnF_ephInPR"
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)  # Initial hidden state\n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)  # Initial cell state\n",
    "        out, _ = self.lstm(x, (h0, c0))  # LSTM forward\n",
    "        out = self.fc(out[:, -1, :])  # Fully connected layer applied to the last time step\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "T_61IQTUJNQG",
    "outputId": "dface985-5cf7-4dce-f840-1971d74ccf0d"
   },
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the losses for each hidden layer size\n",
    "losses_per_hidden_size = {}\n",
    "\n",
    "# Set initial parameters\n",
    "best_model = None\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Loop over different hidden sizes\n",
    "for hidden_size in hidden_sizes:\n",
    "    model = LSTMModel(input_size, hidden_size, output_size)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Initialize lists for storing epoch losses\n",
    "    train_loss_epoch = []\n",
    "    val_loss_epoch = []\n",
    "\n",
    "    # Training loop\n",
    "    epochs = 100\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train)\n",
    "        loss = criterion(output, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Append training loss for this epoch\n",
    "        train_loss_epoch.append(loss.item())\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_output = model(X_val)\n",
    "        val_loss = criterion(val_output, y_val)\n",
    "        val_loss_epoch.append(val_loss.item())\n",
    "\n",
    "        # Save the best model\n",
    "        if val_loss.item() < best_val_loss:\n",
    "            best_val_loss = val_loss.item()\n",
    "            best_model = model  # Save the best model\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Hidden Size: {hidden_size}, Training Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")\n",
    "\n",
    "    # Store the training and validation losses for this hidden size\n",
    "    losses_per_hidden_size[hidden_size] = (train_loss_epoch, val_loss_epoch)\n",
    "\n",
    "# Plot training and validation loss for each hidden size\n",
    "my_color = ['#FF662A', '#FFA22A', '#82AC26', '#4F3F84']\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, hidden_size in enumerate(hidden_sizes):\n",
    "    train_loss, val_loss = losses_per_hidden_size[hidden_size]\n",
    "    plt.plot(train_loss, color=my_color[i], label=f'Training Loss (Hidden Size {hidden_size})', linestyle='solid')\n",
    "    plt.plot(val_loss, color=my_color[i], label=f'Validation Loss (Hidden Size {hidden_size})', linestyle='dashed')\n",
    "\n",
    "plt.title('Training and Validation Loss for Different Hidden Sizes')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "0yZHzm7APcx3",
    "outputId": "868017e4-b961-41da-dcd6-cfd24b7f0258"
   },
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "test_output = best_model(X_test)\n",
    "test_loss = criterion(test_output, y_test)\n",
    "\n",
    "print(f\"Test Loss: {test_loss.item()}\")\n",
    "\n",
    "# Convert tensors to numpy arrays for plotting\n",
    "y_test_np = y_test.detach().numpy()\n",
    "test_output_np = test_output.detach().numpy()\n",
    "\n",
    "# Plot the true vs predicted time series\n",
    "save_path = '/content/drive/My Drive/predicted_vs_true_timeseries.pdf'\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test_np, label='True Time Series', color='#696969')\n",
    "plt.plot(test_output_np, label='Predicted Time Series', color='#FF5500', linestyle='dashed')\n",
    "plt.title('True vs Predicted Time Series')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "\n",
    "# Save the figure as a PDF file\n",
    "plt.savefig(save_path, format='pdf')\n",
    "\n",
    "print(f\"Figure saved as PDF to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wx9-uoB6ege1"
   },
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)  # Initial hidden state\n",
    "        out, _ = self.gru(x, h0)  # GRU forward\n",
    "        out = self.fc(out[:, -1, :])  # Fully connected layer applied to the last time step\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IUek8ZYSey4_",
    "outputId": "74a2e4e3-a0a3-4c72-e7f2-5ca9bfea213a"
   },
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the losses for each hidden layer size\n",
    "losses_per_hidden_size = {}\n",
    "\n",
    "# Set initial parameters\n",
    "best_model = None\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Loop over different hidden sizes\n",
    "for hidden_size in hidden_sizes:\n",
    "    model = GRUModel(input_size, hidden_size, output_size)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Initialize lists for storing epoch losses\n",
    "    train_loss_epoch = []\n",
    "    val_loss_epoch = []\n",
    "\n",
    "    # Training loop\n",
    "    epochs = 100\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train)\n",
    "        loss = criterion(output, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Append training loss for this epoch\n",
    "        train_loss_epoch.append(loss.item())\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_output = model(X_val)\n",
    "        val_loss = criterion(val_output, y_val)\n",
    "        val_loss_epoch.append(val_loss.item())\n",
    "\n",
    "        # Save the best model\n",
    "        if val_loss.item() < best_val_loss:\n",
    "            best_val_loss = val_loss.item()\n",
    "            best_model = model  # Save the best model\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Hidden Size: {hidden_size}, Training Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")\n",
    "\n",
    "    # Store the training and validation losses for this hidden size\n",
    "    losses_per_hidden_size[hidden_size] = (train_loss_epoch, val_loss_epoch)\n",
    "\n",
    "# Plot training and validation loss for each hidden size\n",
    "my_color = ['#FF662A', '#FFA22A', '#82AC26', '#4F3F84']\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, hidden_size in enumerate(hidden_sizes):\n",
    "    train_loss, val_loss = losses_per_hidden_size[hidden_size]\n",
    "    plt.plot(train_loss, color=my_color[i], label=f'Training Loss (Hidden Size {hidden_size})', linestyle='solid')\n",
    "    plt.plot(val_loss, color=my_color[i], label=f'Validation Loss (Hidden Size {hidden_size})', linestyle='dashed')\n",
    "\n",
    "plt.title('Training and Validation Loss for Different Hidden Sizes')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "DImaxjQAifEA",
    "outputId": "713f4129-24dc-4dcf-b688-3807025e7021"
   },
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "test_output = best_model(X_test)\n",
    "test_loss = criterion(test_output, y_test)\n",
    "\n",
    "print(f\"Test Loss: {test_loss.item()}\")\n",
    "\n",
    "# Convert tensors to numpy arrays for plotting\n",
    "y_test_np = y_test.detach().numpy()\n",
    "test_output_np = test_output.detach().numpy()\n",
    "\n",
    "# Plot the true vs predicted time series\n",
    "save_path = '/content/drive/My Drive/predicted_vs_true_timeseries.pdf'\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test_np, label='True Time Series', color='#696969')\n",
    "plt.plot(test_output_np, label='Predicted Time Series', color='#FF5500', linestyle='dashed')\n",
    "plt.title('True vs Predicted Time Series')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "\n",
    "# Save the figure as a PDF file\n",
    "plt.savefig(save_path, format='pdf')\n",
    "\n",
    "print(f\"Figure saved as PDF to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
